{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Previsao de Embarque \r\n",
        "- Simples \r\n",
        "- Sem Serie Temporal\r\n",
        "- Regressao Linear\r\n",
        "- Random Forest"
      ],
      "metadata": {},
      "id": "cb33d1de-7a2c-42c9-ace8-56f64b8c5847"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, StackingRegressor, GradientBoostingRegressor\r\n",
        "from sklearn.pipeline import make_pipeline\r\n",
        "from sklearn.datasets import make_regression\r\n",
        "\r\n",
        "import warnings\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\r\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\r\n",
        "#from sklearn.metrics import mean_absolute_percentage_error\r\n",
        "from sklearn.model_selection import RandomizedSearchCV\r\n",
        "from IPython.display import display\r\n",
        "from pprint import pprint\r\n",
        "from math import sqrt\r\n",
        "\r\n",
        "#from shutil import unpack_archive\r\n",
        "#unpack_archive('./df_input.zip', './')"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1629676240232
        }
      },
      "id": "590f3a91-077c-483c-8472-063d0d47c026"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtro de Onibus e definicoes de features/target"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "869d1469-9da1-453e-bdf1-39e6456a90f0"
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading Data file (geolocalized)\r\n",
        "data = pd.read_csv('./df_input.csv', sep=';', delimiter=';')\r\n",
        "\r\n",
        "busline_filter = 41\r\n",
        "data_model = data.copy()\r\n",
        "\r\n",
        "feature_names = [\r\n",
        "    'hour_sin', 'hour_cos', \r\n",
        "    'd_mes', 'd_ano', 'mes', 'semana_do_mes', \r\n",
        "    'domingo','segunda', 'terca', 'quarta', 'quinta', 'sexta', 'sabado', \r\n",
        "    'feriado', 'vespera_feriado']\r\n",
        "\r\n",
        "target = 'validations_per_hour'"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629676244601
        }
      },
      "id": "5e22e982-8dfb-4a0d-aea8-afb0a085ceb3"
    },
    {
      "cell_type": "code",
      "source": [
        "day_of_week_translator = {\n",
        "    0: \"Domingo\",\n",
        "    1: \"Segunda\",\n",
        "    2: \"Terca\",\n",
        "    3: \"Quarta\",\n",
        "    4: \"Quinta\",\n",
        "    5: \"Sexta\",\n",
        "    6: \"Sabado\"\n",
        "}\n",
        "\n",
        "feriados = [\n",
        "            ['Ano Novo', 1, 1],\n",
        "            ['Carnaval', 24, 2],\n",
        "            ['Carnaval', 25, 2],\n",
        "            ['Carnaval', 26, 2],\n",
        "            ['Dia de São José', 19, 3],\n",
        "            ['Data Magna', 25, 3],\n",
        "            ['Sexta-Feira Santa', 10, 4],\n",
        "            ['Aniversário de Fortaleza', 13, 4],\n",
        "            ['Tiradentes', 21, 4],\n",
        "            ['Dia do Trabalho', 1, 5],\n",
        "            ['Corpus Christi', 28, 5],\n",
        "            ['N. Senhora da Assunção', 27, 5],\n",
        "            ['Independência do Brasil', 7, 9],\n",
        "            ['N. Senhora de Aparecida', 12, 10],\n",
        "            ['Dia de Finados', 2, 11],\n",
        "            ['Proclamação da Republica', 15, 11],\n",
        "            ['Natal', 25, 12],\n",
        "]\n",
        "\n",
        "vesperas = [\n",
        "            ['Ano Novo', 31, 12],\n",
        "            ['Carnaval', 23, 2],\n",
        "            ['Dia de São José', 18, 3],\n",
        "            ['Data Magna', 24, 3],\n",
        "            ['Sexta-Feira Santa', 9, 4],\n",
        "            ['Aniversário de Fortaleza', 12, 4],\n",
        "            ['Tiradentes', 20, 4],\n",
        "            ['Dia do Trabalho', 30, 4],\n",
        "            ['N. Senhora da Assunção', 26, 5],\n",
        "            ['Independência do Brasil', 6, 9],\n",
        "            ['N. Senhora de Aparecida', 11, 10],\n",
        "            ['Dia de Finados', 1, 11],\n",
        "            ['Proclamação da Republica', 14, 11],\n",
        "            ['Natal', 24, 12],\n",
        "]"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1629676244801
        }
      },
      "id": "fa96d5ca-4a79-4bc9-849d-a47e61639274"
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoder = OneHotEncoder(sparse=False)\r\n",
        "\r\n",
        "data_model[['domingo','segunda', 'terca', 'quarta', 'quinta', 'sexta', 'sabado']] = one_hot_encoder.fit_transform(data_model['d_semana'].values.reshape(-1,1))\r\n",
        "data_model['feriado'] = [1 if any((x[0] == d and x[1] == m) for (_, d, m) in feriados) else 0 for x in list(zip(data_model.d_mes, data_model.mes))]\r\n",
        "data_model['vespera_feriado'] = [1 if any((x[0] == d and x[1] == m) for (_, d, m) in vesperas) else 0 for x in list(zip(data_model.d_mes, data_model.mes))]\r\n",
        "\r\n",
        "line_data_model = data_model.loc[data['linha'] == busline_filter].copy()\r\n",
        "\r\n",
        "X = line_data_model.filter(feature_names, axis=1)\r\n",
        "y = line_data_model.validations_per_hour"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1629676254210
        }
      },
      "id": "6bce8a86-d991-4364-96e9-dbd3e82084e3"
    },
    {
      "cell_type": "code",
      "source": [
        "display(line_data_model)\r\n",
        "display(X)\r\n",
        "display(y)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "cbda2dde-fe1d-4c91-823e-c1d4f1af5ec1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------------------------------------------------- Fim Setup ----------------------------------------------------------------------------  \r\n",
        "# Criacao dos Modelos"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "72de803e-424a-42c5-9ba4-dab62dd89ab1"
    },
    {
      "cell_type": "code",
      "source": [
        "def singlebusline_model(model, X, y):\r\n",
        "    singlebusline_model = model\r\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2, random_state=5)\r\n",
        "    singlebusline_model.fit(X_train, Y_train)\r\n",
        "    performance_scoring = get_performance(model, X_test, Y_test)\r\n",
        "    return singlebusline_model, performance_scoring\r\n",
        "\r\n",
        "def get_performance(model, X_test, Y_test):\r\n",
        "    y_test_predict = model.predict(X_test)\r\n",
        "    mse = mean_squared_error(Y_test, y_test_predict)\r\n",
        "    rmse = (np.sqrt(mse))\r\n",
        "    r2 = r2_score(Y_test, y_test_predict)\r\n",
        "    mae = mean_absolute_error(Y_test, y_test_predict)\r\n",
        "    #mape = mean_absolute_percentage_error(Y_test, y_test_predict)\r\n",
        "    performance_scoring = [\r\n",
        "        r2,\r\n",
        "        rmse,\r\n",
        "        mae,\r\n",
        "        #mape\r\n",
        "    ]\r\n",
        "    #performance_scoring = pd.DataFrame(performance_scoring,columns=['Metrica', 'Score'])\r\n",
        "    #performance_scoring['Score'] = performance_scoring['Score'].astype('float64')\r\n",
        "    return performance_scoring"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629676254801
        }
      },
      "id": "871f0085-01e9-4694-9d3e-0210e260c87f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid Search"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "4dae3130-a63c-4ac7-a471-a1e428809d7b"
    },
    {
      "cell_type": "code",
      "source": [
        "LinearRegressionModel = LinearRegression()\r\n",
        "RandomForestModel = RandomForestRegressor()"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629676800525
        }
      },
      "id": "2d8e04cf-b35c-4d00-8a55-c96e1863e9d5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Linear Regression Model Parameters"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "42cb2b42-702e-4ddb-943a-dd4d6e5b8f01"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Linear Regression  Params ----> \")\r\n",
        "pprint(LinearRegressionModel.get_params())\r\n",
        "\r\n",
        "copy_X = [True, False]\r\n",
        "fit_intercept = [True, False]\r\n",
        "n_jobs = [2, 4, 6, 8]\r\n",
        "normalize = [True, False]\r\n",
        "\r\n",
        "\r\n",
        "# Create the random grid\r\n",
        "random_grid_linearregression = {'copy_X': copy_X, 'fit_intercept': fit_intercept, 'n_jobs': n_jobs, 'normalize': normalize}\r\n",
        "\r\n",
        "print(\"Random Grid - LINEAR REGRESSION\")\r\n",
        "pprint(random_grid_linearregression)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression  Params ----> \n",
            "{'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'normalize': False}\n",
            "Random Grid - LINEAR REGRESSION\n",
            "{'copy_X': [True, False],\n",
            " 'fit_intercept': [True, False],\n",
            " 'n_jobs': [2, 4, 6, 8],\n",
            " 'normalize': [True, False]}\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629676801540
        }
      },
      "id": "bc5966c3-11f4-43e0-8f23-fc3a3da37702"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Forest Model Parameters"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "62959193-309d-45aa-9882-5c798cf85fcf"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Random Forest Model Params ----> \")\r\n",
        "pprint(RandomForestModel.get_params())\r\n",
        "\r\n",
        "# Number of trees in random forest\r\n",
        "n_estimators = [int(x) for x in np.linspace(start = 20, stop = 1000, num = 10)]\r\n",
        "\r\n",
        "n_jobs = [2, 4, 6, 8]\r\n",
        "\r\n",
        "# Number of features to consider at every split\r\n",
        "max_features = ['auto', 'sqrt']\r\n",
        "\r\n",
        "# Maximum number of levels in tree\r\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\r\n",
        "max_depth.append(None)\r\n",
        "\r\n",
        "# Minimum number of samples required to split a node\r\n",
        "min_samples_split = [2, 5, 10]\r\n",
        "\r\n",
        "# Minimum number of samples required at each leaf node\r\n",
        "min_samples_leaf = [1, 2, 4]\r\n",
        "\r\n",
        "# Method of selecting samples for training each tree\r\n",
        "bootstrap = [True, False]\r\n",
        "\r\n",
        "# Create the random grid\r\n",
        "random_grid_randomforest = {'n_estimators': n_estimators,\r\n",
        "               'max_features': max_features,\r\n",
        "               'max_depth': max_depth,\r\n",
        "               'min_samples_split': min_samples_split,\r\n",
        "               'min_samples_leaf': min_samples_leaf,\r\n",
        "               'bootstrap': bootstrap,\r\n",
        "               'n_jobs': n_jobs}\r\n",
        "\r\n",
        "print(\"Random Grid - RANDOM FOREST\")\r\n",
        "pprint(random_grid_randomforest)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Model Params ----> \n",
            "{'bootstrap': True,\n",
            " 'ccp_alpha': 0.0,\n",
            " 'criterion': 'mse',\n",
            " 'max_depth': None,\n",
            " 'max_features': 'auto',\n",
            " 'max_leaf_nodes': None,\n",
            " 'max_samples': None,\n",
            " 'min_impurity_decrease': 0.0,\n",
            " 'min_impurity_split': None,\n",
            " 'min_samples_leaf': 1,\n",
            " 'min_samples_split': 2,\n",
            " 'min_weight_fraction_leaf': 0.0,\n",
            " 'n_estimators': 100,\n",
            " 'n_jobs': None,\n",
            " 'oob_score': False,\n",
            " 'random_state': None,\n",
            " 'verbose': 0,\n",
            " 'warm_start': False}\n",
            "Random Grid - RANDOM FOREST\n",
            "{'bootstrap': [True, False],\n",
            " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
            " 'max_features': ['auto', 'sqrt'],\n",
            " 'min_samples_leaf': [1, 2, 4],\n",
            " 'min_samples_split': [2, 5, 10],\n",
            " 'n_estimators': [20, 128, 237, 346, 455, 564, 673, 782, 891, 1000],\n",
            " 'n_jobs': [2, 4, 6, 8]}\n"
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629676803747
        }
      },
      "id": "6485223f-efbf-48ee-9f5f-3b728871a9ed"
    },
    {
      "cell_type": "code",
      "source": [
        "# Random search of parameters, using 3 fold cross validation, \r\n",
        "# search across 100 different combinations, and use all available cores\r\n",
        "#LinearRegressionModel = LinearRegression()\r\n",
        "#RandomForestModel = RandomForestRegressor()\r\n",
        "gridsearch_result_randomforest = RandomizedSearchCV(estimator = RandomForestModel, param_distributions = random_grid_randomforest, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\r\n",
        "gridsearch_result_linearregression = RandomizedSearchCV(estimator = LinearRegressionModel, param_distributions = random_grid_linearregression, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\r\n",
        "\r\n",
        "# Fit the random search model\r\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2, random_state=5)\r\n",
        "\r\n",
        "gridsearch_result_randomforest.fit(X_train, Y_train)\r\n",
        "gridsearch_result_linearregression.fit(X_train, Y_train)\r\n",
        "\r\n",
        "print(\"Random Forest Best Parameters -----> \")\r\n",
        "pprint(gridsearch_result_randomforest.best_params_)\r\n",
        "\r\n",
        "print(\"Linear Regression Best Parameters -----> \")\r\n",
        "pprint(gridsearch_result_linearregression.best_params_)\r\n",
        "\r\n",
        "best_random_randomforest = gridsearch_result_randomforest.best_estimator_\r\n",
        "best_random_linearregression = gridsearch_result_linearregression.best_estimator_\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
            "Linear Regression Best Parameters -----> \n",
            "{'copy_X': True, 'fit_intercept': False, 'n_jobs': 2, 'normalize': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/sklearn/model_selection/_search.py:277: UserWarning: The total space of parameters 32 is smaller than n_iter=100. Running 32 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    0.8s\n",
            "[Parallel(n_jobs=-1)]: Done  96 out of  96 | elapsed:    0.9s finished\n"
          ]
        }
      ],
      "execution_count": 19,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629678288912
        }
      },
      "id": "f775c71d-f8ed-459b-a4e3-1569d6fa6a00"
    },
    {
      "cell_type": "code",
      "source": [
        "sample = X.sample(n=1)\r\n",
        "sample"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "         hour_sin  hour_cos  d_mes  d_ano  mes  semana_do_mes  domingo  \\\n1018497  0.887885  0.460065      7    281   10              1      0.0   \n\n         segunda  terca  quarta  quinta  sexta  sabado  feriado  \\\n1018497      0.0    1.0     0.0     0.0    0.0     0.0        0   \n\n         vespera_feriado  \n1018497                0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hour_sin</th>\n      <th>hour_cos</th>\n      <th>d_mes</th>\n      <th>d_ano</th>\n      <th>mes</th>\n      <th>semana_do_mes</th>\n      <th>domingo</th>\n      <th>segunda</th>\n      <th>terca</th>\n      <th>quarta</th>\n      <th>quinta</th>\n      <th>sexta</th>\n      <th>sabado</th>\n      <th>feriado</th>\n      <th>vespera_feriado</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1018497</th>\n      <td>0.887885</td>\n      <td>0.460065</td>\n      <td>7</td>\n      <td>281</td>\n      <td>10</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629678293015
        }
      },
      "id": "b97a4671-b20c-4109-bf85-0e1d8df65a2c"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"###  1 Modelo Por Linha (dado completo de treino)\")\r\n",
        "\r\n",
        "model_per_line_lr, model_per_line_lr_performance = singlebusline_model(LinearRegressionModel, X, y)\r\n",
        "model_per_line_rf, model_per_line_rf_performance = singlebusline_model(RandomForestModel, X, y)\r\n",
        "print(\"\\n----------------------------------------------------\\n\")\r\n",
        "print('Regressao Linear [DEFAULT]: \\n', model_per_line_lr_performance)\r\n",
        "print(\"\\n----------------------------------------------------\\n\")\r\n",
        "print('Random Forest [DEFAULT]: \\n', model_per_line_rf_performance)\r\n",
        "print(\"\\n----------------------------------------------------\\n\")\r\n",
        "print('Regressao Linear [GRID SEARCH]: \\n', get_performance(best_random_randomforest, X_test,Y_test))\r\n",
        "print(\"\\n----------------------------------------------------\\n\")\r\n",
        "print('Random Forest [GRID SEARCH]: \\n', get_performance(best_random_linearregression, X_test,Y_test))\r\n",
        "print(\"\\n----------------------------------------------------\\n\")\r\n",
        "\r\n",
        "print(\"\\nUtilizando sample aleatorio de dado para teste de previsao: \")\r\n",
        "\r\n",
        "predict_res = model_per_line_lr.predict(sample)\r\n",
        "\r\n",
        "print(\"Regressao Linear -> resultado do predict de test: \", predict_res)\r\n",
        "\r\n",
        "predict_res2 = model_per_line_rf.predict(sample)\r\n",
        "print(\"Random Forest -> resultado do predict de test: \", predict_res2)\r\n",
        "\r\n",
        "random_res = best_random_randomforest.predict(sample)\r\n",
        "print(\"Random Forest Best Grid Searched -> resultado do predict de test: \", predict_res2)\r\n",
        "\r\n",
        "random_res = best_random_linearregression.predict(sample)\r\n",
        "print(\"Linear Regression Best Grid Searched -> resultado do predict de test: \", predict_res2)\r\n",
        "\r\n",
        "display(data_model.loc[sample.index[0]:sample.index[0]])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###  1 Modelo Por Linha (dado completo de treino)\n",
            "Regressao Linear [DEFAULT]: \n",
            " [0.3724476627164204, 215.73460401278615, 161.58880229914652]\n",
            "\n",
            "----------------------------------------------------\n",
            "\n",
            "Random Forest [DEFAULT]: \n",
            " [0.9772059277834443, 41.115520837086784, 29.505570859841917]\n",
            "Regressao Linear [GRID SEARCH]: \n",
            " [0.9770620467299195, 41.24508168047433, 29.59751188904919]\n",
            "\n",
            "----------------------------------------------------\n",
            "\n",
            "Random Forest [GRID SEARCH]: \n",
            " [0.37244766271642116, 215.734604012786, 161.58880229914632]\n",
            "\n",
            "Utilizando sample aleatorio de dado para teste de previsao: \n",
            "Regressao Linear -> resultado do predict de test:  [325.31825494]\n",
            "Random Forest -> resultado do predict de test:  [48.83]\n",
            "Random Forest Best Grid Searched -> resultado do predict de test:  [48.83]\n",
            "Linear Regression Best Grid Searched -> resultado do predict de test:  [48.83]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "         linha            data_hora  validations_per_hour  d_semana  hour_sin  \\\n1018497     41  2020-10-07 04:00:00                    47         2  0.887885   \n\n         hour_cos  hora  d_mes  d_ano  mes  semana_do_mes  domingo  segunda  \\\n1018497  0.460065     4      7    281   10              1      0.0      0.0   \n\n         terca  quarta  quinta  sexta  sabado  feriado  vespera_feriado  \n1018497    1.0     0.0     0.0    0.0     0.0        0                0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>linha</th>\n      <th>data_hora</th>\n      <th>validations_per_hour</th>\n      <th>d_semana</th>\n      <th>hour_sin</th>\n      <th>hour_cos</th>\n      <th>hora</th>\n      <th>d_mes</th>\n      <th>d_ano</th>\n      <th>mes</th>\n      <th>semana_do_mes</th>\n      <th>domingo</th>\n      <th>segunda</th>\n      <th>terca</th>\n      <th>quarta</th>\n      <th>quinta</th>\n      <th>sexta</th>\n      <th>sabado</th>\n      <th>feriado</th>\n      <th>vespera_feriado</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1018497</th>\n      <td>41</td>\n      <td>2020-10-07 04:00:00</td>\n      <td>47</td>\n      <td>2</td>\n      <td>0.887885</td>\n      <td>0.460065</td>\n      <td>4</td>\n      <td>7</td>\n      <td>281</td>\n      <td>10</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1629678491059
        }
      },
      "id": "19ec5db2-903e-4d5e-ac06-e218249b1bdd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BAGGING"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "4b8fd889-6b65-486c-8d1a-6b7f0d298400"
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2, random_state=5)\r\n",
        "warnings.filterwarnings(\"ignore\") # To ignore warnings\r\n",
        "n_jobs = -1 # This parameter conrols the parallel processing. -1 means using all processors.\r\n",
        "random_state = 42 # This parameter controls the randomness of the data. Using some int value to get same results everytime this code is run\r\n",
        "models_scores = [] # To store model scores\r\n",
        "\r\n",
        "def rmse(model):\r\n",
        "    model.fit(X_train, Y_train)\r\n",
        "    y_pred = model.predict(X_test)\r\n",
        "    \r\n",
        "    return mean_squared_error(Y_test, y_pred, squared= False) # squared= False > returns Root Mean Square Error                  \r\n",
        "\r\n",
        "def bagging_predictions(estimator):\r\n",
        "    \"\"\"\r\n",
        "    I/P\r\n",
        "    estimator: The base estimator from which the ensemble is grown.\r\n",
        "    O/P\r\n",
        "    br_y_pred: Predictions on test data for the base estimator.\r\n",
        "    \r\n",
        "    \"\"\"\r\n",
        "    regr = BaggingRegressor(base_estimator=estimator,\r\n",
        "                            n_estimators=10,\r\n",
        "                            max_samples=1.0,\r\n",
        "                            bootstrap=True, # Samples are drawn with replacement\r\n",
        "                            n_jobs= n_jobs,\r\n",
        "                            random_state=random_state).fit(X_train, Y_train)\r\n",
        "\r\n",
        "    br_y_pred = regr.predict(X_test)\r\n",
        "\r\n",
        "    rmse_val = mean_squared_error(Y_test, br_y_pred, squared= False) # squared= False > returns Root Mean Square Error   \r\n",
        "\r\n",
        "    print(f'RMSE for base estimator {regr.base_estimator_} = {rmse_val}\\n')\r\n",
        "    return br_y_pred\r\n",
        "\r\n",
        "linear_regression = make_pipeline(LinearRegression())\r\n",
        "rf_regressor = make_pipeline(RandomForestRegressor())\r\n",
        "#rf_regressor = make_pipeline(RandomForestRegressor())\r\n",
        "\r\n",
        "predictions = np.column_stack((bagging_predictions(linear_regression),\r\n",
        "                              bagging_predictions(rf_regressor),))\r\n",
        "\r\n",
        "print(f\"Bagged predictions shape: {predictions.shape}\")\r\n",
        "       \r\n",
        "y_pred = np.mean(predictions, axis=1)\r\n",
        "print(\"Aggregated predictions (y_pred) shape\", y_pred.shape)\r\n",
        "\r\n",
        "rmse_val = mean_squared_error(Y_test, y_pred, squared= False) # squared= False > returns Root Mean Square Error   \r\n",
        "models_scores.append(['Bagging', rmse_val])\r\n",
        "\r\n",
        "print(f'\\nBagging RMSE= {rmse_val}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE for base estimator Pipeline(memory=None,\n",
            "         steps=[('linearregression',\n",
            "                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
            "                                  normalize=False))],\n",
            "         verbose=False) = 215.75112692985846\n",
            "\n",
            "RMSE for base estimator Pipeline(memory=None,\n",
            "         steps=[('randomforestregressor',\n",
            "                 RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
            "                                       criterion='mse', max_depth=None,\n",
            "                                       max_features='auto', max_leaf_nodes=None,\n",
            "                                       max_samples=None,\n",
            "                                       min_impurity_decrease=0.0,\n",
            "                                       min_impurity_split=None,\n",
            "                                       min_samples_leaf=1, min_samples_split=2,\n",
            "                                       min_weight_fraction_leaf=0.0,\n",
            "                                       n_estimators=100, n_jobs=None,\n",
            "                                       oob_score=False, random_state=None,\n",
            "                                       verbose=0, warm_start=False))],\n",
            "         verbose=False) = 43.38972377873261\n",
            "\n",
            "Bagged predictions shape: (1235, 2)\n",
            "Aggregated predictions (y_pred) shape (1235,)\n",
            "\n",
            "Bagging RMSE= 113.48131248884687\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629252622668
        }
      },
      "id": "7808b1b3-dc28-4d3f-8b14-15781bd7f294"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STACKING"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "731700fd-b25f-4051-a677-e5e8cdf17363"
    },
    {
      "cell_type": "code",
      "source": [
        "estimators = [ ('random_forest', rf_regressor), ('linear_reg', linear_regression)]\r\n",
        "\r\n",
        "stack = StackingRegressor(estimators=estimators, final_estimator= rf_regressor, cv= 5, n_jobs= n_jobs, passthrough = True)\r\n",
        "\r\n",
        "stack.fit(X_train, Y_train)\r\n",
        "\r\n",
        "pred = stack.predict(X_test)\r\n",
        "\r\n",
        "rmse_val = mean_squared_error(Y_test, pred, squared= False) # squared= False > returns Root Mean Square Error    \r\n",
        "models_scores.append(['Stacking', rmse_val])\r\n",
        "print(f'rmse= {rmse_val}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rmse= 40.124796479651025\n"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629253092081
        }
      },
      "id": "47711335-0579-4ce4-a2a8-3dbdd690125c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BOOSTING"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "59d186e1-0c00-4178-9028-d5ba275f5563"
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_boosting_regressor= GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\r\n",
        "                                   max_depth=4, max_features='sqrt',\r\n",
        "                                   min_samples_leaf=15, min_samples_split=10, \r\n",
        "                                   loss='huber', random_state = random_state)\r\n",
        "\r\n",
        "score = rmse(gradient_boosting_regressor)\r\n",
        "models_scores.append(['GradientBoostingRegressor', score])\r\n",
        "print(f'GradientBoostingRegressor Score= {score}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GradientBoostingRegressor Score= 45.585891583534995\n"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629253106634
        }
      },
      "id": "b773e04f-0613-494a-b113-f7c357b0fb39"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ranking Linhas de Onibus"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "f0ebeee3-574e-4540-a5f9-554c9be63133"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "b42e89f7-8097-473f-80db-e9e7f486e3c1"
    },
    {
      "cell_type": "code",
      "source": [
        "#data_model\r\n",
        "#data_model.loc[data['linha'] == busline_filter].copy()\r\n",
        "print(data_model.linha.value_counts(ascending=True)[data_model['linha'].value_counts() < 100])\r\n",
        "linha_lista = data_model.linha.unique()\r\n",
        "\r\n",
        "#linha_lista = linha_lista[:5]\r\n",
        "res_map = list()\r\n",
        "for linha in linha_lista:\r\n",
        "    #print(linha) it is working\r\n",
        "    currentLinhaData = data_model.loc[data['linha'] == linha].copy()\r\n",
        "    #print(len(currentLinhaData))\r\n",
        "    if len(currentLinhaData) < 10:\r\n",
        "        continue\r\n",
        "    X = currentLinhaData.filter(['hour_sin', 'hour_cos', \r\n",
        "    'd_mes', 'd_ano', 'mes', 'semana_do_mes', \r\n",
        "    'domingo','segunda', 'terca', 'quarta', 'quinta', 'sexta', 'sabado', \r\n",
        "    'feriado', 'vespera_feriado'], axis=1)\r\n",
        "    y = currentLinhaData.validations_per_hour\r\n",
        "\r\n",
        "    #FAZER TODOS OS MODELOS PARA AS LINHAS E ADICIONAR NA TABELA PRINCIPAL\r\n",
        "    #RANDOM FOREST COM GRID SEARCH\r\n",
        "    #LINEAR REGRESSION COM GRID SEARCH\r\n",
        "    #BAGGING STACKING AND BOOSTING\r\n",
        "    #\r\n",
        "    model, performance = singlebusline_model(RandomForestModel, X, y)\r\n",
        "    performance.insert(0, linha)\r\n",
        "    res_map.append(performance)\r\n",
        "\r\n",
        "res_map = pd.DataFrame(res_map,columns=['Linha', '[RF][GS]R2', '[RF][GS]RMSE', '[RF][GS]MAE',\r\n",
        "    '[LR][GS]R2', '[LR][GS]RMSE', '[LR][GS]MAE',\r\n",
        "    '[BAG][GS]R2', '[BAG][GS]RMSE', '[BAG][GS]MAE',\r\n",
        "    '[STK][GS]R2', '[STK][GS]RMSE', '[STK][GS]MAE',\r\n",
        "    '[BOS][GS]R2', '[BOS][GS]RMSE', '[BOS][GS]MAE' ])\r\n",
        "\r\n",
        "#performance_scoring['Score'] = performance_scoring['Score'].astype('float64')\r\n",
        "res_map = res_map.sort_values('R2').reset_index(drop=True)\r\n",
        "res_map"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "941     1\n",
            "233     1\n",
            "811     1\n",
            "202     1\n",
            "935     1\n",
            "       ..\n",
            "140    69\n",
            "40     76\n",
            "999    79\n",
            "91     81\n",
            "33     84\n",
            "Name: linha, Length: 63, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "     Linha         R2       RMSE        MAE\n0      999 -36.631640  70.745044  41.141250\n1      145  -7.249889   6.259950   5.577500\n2       47  -3.948501   2.558021   1.709091\n3      413  -3.481755  26.462695  21.495000\n4      138  -3.076205  12.875002  12.593333\n..     ...        ...        ...        ...\n353     38   0.976998  30.804185  20.014910\n354    757   0.977344  30.453935  20.463345\n355    345   0.978740  14.837540   9.744331\n356    660   0.979762  27.644751  17.924536\n357     76   0.981766  33.648133  23.257582\n\n[358 rows x 4 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Linha</th>\n      <th>R2</th>\n      <th>RMSE</th>\n      <th>MAE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>999</td>\n      <td>-36.631640</td>\n      <td>70.745044</td>\n      <td>41.141250</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>145</td>\n      <td>-7.249889</td>\n      <td>6.259950</td>\n      <td>5.577500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47</td>\n      <td>-3.948501</td>\n      <td>2.558021</td>\n      <td>1.709091</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>413</td>\n      <td>-3.481755</td>\n      <td>26.462695</td>\n      <td>21.495000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>138</td>\n      <td>-3.076205</td>\n      <td>12.875002</td>\n      <td>12.593333</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>353</th>\n      <td>38</td>\n      <td>0.976998</td>\n      <td>30.804185</td>\n      <td>20.014910</td>\n    </tr>\n    <tr>\n      <th>354</th>\n      <td>757</td>\n      <td>0.977344</td>\n      <td>30.453935</td>\n      <td>20.463345</td>\n    </tr>\n    <tr>\n      <th>355</th>\n      <td>345</td>\n      <td>0.978740</td>\n      <td>14.837540</td>\n      <td>9.744331</td>\n    </tr>\n    <tr>\n      <th>356</th>\n      <td>660</td>\n      <td>0.979762</td>\n      <td>27.644751</td>\n      <td>17.924536</td>\n    </tr>\n    <tr>\n      <th>357</th>\n      <td>76</td>\n      <td>0.981766</td>\n      <td>33.648133</td>\n      <td>23.257582</td>\n    </tr>\n  </tbody>\n</table>\n<p>358 rows × 4 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1629252765141
        }
      },
      "id": "1041cc61-251f-48c5-99c9-42ee7499027d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliacao dos dados atualmente\r\n",
        "404 linhas  \r\n",
        "358 com pelo menos 10 exemplos\r\n",
        "\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "bd279b72-5495-477e-9a31-f461d80c63eb"
    },
    {
      "cell_type": "code",
      "source": [
        "res_map.to_csv('./classic-linha-comp.csv', index = False)"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1629252765312
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "a4866fd1-9383-472d-9bb2-f32bcb6bfb0e"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "1b038eb4-08d3-4f90-b184-e0a4f29c99f9"
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "4caa081543ae4d7454eea2adf6270962382d99fc25b3a6423caed7aecce4d7f8"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}